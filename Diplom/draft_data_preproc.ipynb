{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "random.seed(1228)\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "import numpy as np\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 analize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_raw22.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>relevant</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\\tЯ очень расстроена! Пошли в межсерверную бит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>\\tУважаемые разработчики, благодарю за ваш отв...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>\\tИграю с ноября. До сих пор не надоедает. Доб...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>\\tУ меня Клара виснит,она бывает прозрачной ил...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>\\tЛучшая игра!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  rank  relevant                                               text\n",
       "0   1     1         1  \\tЯ очень расстроена! Пошли в межсерверную бит...\n",
       "1   2     5         1  \\tУважаемые разработчики, благодарю за ваш отв...\n",
       "2   3     5         1  \\tИграю с ноября. До сих пор не надоедает. Доб...\n",
       "3   4     2         1  \\tУ меня Клара виснит,она бывает прозрачной ил...\n",
       "4   5     5         0                                     \\tЛучшая игра!"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      "id          200 non-null int64\n",
      "rank        200 non-null int64\n",
      "relevant    200 non-null int64\n",
      "text        200 non-null object\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 6.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    114\n",
       "0     86\n",
       "Name: relevant, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['relevant'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>relevant</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>я очень расстроена! пошли в межсерверную битв...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>уважаемые разработчики, благодарю за ваш отве...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>играю с ноября  до сих пор не надоедает  доба...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>у меня клара виснит,она бывает прозрачной или...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>лучшая игра!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  rank  relevant                                               text\n",
       "0   1     1         1   я очень расстроена! пошли в межсерверную битв...\n",
       "1   2     5         1   уважаемые разработчики, благодарю за ваш отве...\n",
       "2   3     5         1   играю с ноября  до сих пор не надоедает  доба...\n",
       "3   4     2         1   у меня клара виснит,она бывает прозрачной или...\n",
       "4   5     5         0                                       лучшая игра!"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardize_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[^А-Яа-я0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\", \"at\")\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    return df\n",
    "\n",
    "data = standardize_text(data, \"text\")\n",
    "\n",
    "data.to_csv(\"clean_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>relevant</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>удалил  неделю мучить один уровень, это слишк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>к сожалению дойдя до 25 уровня   стало ясно, ч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>зачем такие сложные уровни? игра раздражает! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>появился минус после обновлений, добавления с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>игра в принципе интересная, но! она заточена ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   id  rank  relevant  \\\n",
       "195         195  196     1         1   \n",
       "196         196  197     2         1   \n",
       "197         197  198     1         1   \n",
       "198         198  199     4         1   \n",
       "199         199  200     2         1   \n",
       "\n",
       "                                                  text  \n",
       "195   удалил  неделю мучить один уровень, это слишк...  \n",
       "196  к сожалению дойдя до 25 уровня   стало ясно, ч...  \n",
       "197   зачем такие сложные уровни? игра раздражает! ...  \n",
       "198   появился минус после обновлений, добавления с...  \n",
       "199   игра в принципе интересная, но! она заточена ...  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = pd.read_csv(\"clean_data.csv\")\n",
    "clean_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    200.000000\n",
       "mean     153.460000\n",
       "std      145.063037\n",
       "min        6.000000\n",
       "25%       34.750000\n",
       "50%      109.500000\n",
       "75%      226.750000\n",
       "max      502.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_data = clean_data.text.apply(len)\n",
    "len_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f5fb5f94c143b7b80ab6a36b9ce829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('не', 175)\n",
      "('и', 149)\n",
      "('в', 101)\n",
      "('игра', 81)\n",
      "('я', 70)\n",
      "('что', 64)\n",
      "('а', 60)\n",
      "('на', 60)\n",
      "('за', 42)\n",
      "('с', 42)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "cnt = Counter()\n",
    "n_types = []\n",
    "n_tokens = []\n",
    "tokens = []\n",
    "for index, row in tqdm(clean_data.iterrows(), total = len(clean_data)):\n",
    "    tokens = row['text'].split()\n",
    "    cnt.update(tokens)\n",
    "    n_types.append(len(cnt))\n",
    "    n_tokens.append(sum(cnt.values()))\n",
    "for i in cnt.most_common(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization, lemmatisation, delete stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystopwords = stopwords.words('russian') + ['это', 'наш' , 'тыс', 'млн', 'млрд', 'также',  'т', 'д', \n",
    "                                            'мой', 'очень', 'день', ',', 'просто', 'этот', 'вообще']\n",
    "def  remove_stopwords(text, mystopwords = mystopwords):\n",
    "    try:\n",
    "        return \" \".join([token for token in text.split() if not token in mystopwords])\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.text = clean_data.text.apply(remove_stopwords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68213ca779445809da0833dd4263224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('игра', 81)\n",
      "('игру', 14)\n",
      "('спасибо', 12)\n",
      "('играть', 12)\n",
      "('уровни', 11)\n",
      "('время', 10)\n",
      "('несколько', 10)\n",
      "('игре', 10)\n",
      "('времени', 10)\n",
      "('пройти', 10)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "cnt = Counter()\n",
    "n_types = []\n",
    "n_tokens = []\n",
    "tokens = []\n",
    "for index, row in tqdm(clean_data.iterrows(), total = len(clean_data)):\n",
    "    tokens = row['text'].split()\n",
    "    cnt.update(tokens)\n",
    "    n_types.append(len(cnt))\n",
    "    n_tokens.append(sum(cnt.values()))\n",
    "for i in cnt.most_common(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 ms, sys: 10.7 ms, total: 30.3 ms\n",
      "Wall time: 1.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from pymystem3 import Mystem\n",
    "\n",
    "m = Mystem()\n",
    "def lemmatize(text, mystem=m):\n",
    "    try:\n",
    "        return \"\".join(m.lemmatize(text)).strip()  \n",
    "    except:\n",
    "        return \" \"\n",
    "\n",
    "clean_data.text = clean_data.text.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>relevant</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>расстраивать! пойти межсерверный битва, случат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>уважаемый разработчик, благодарить ваш ответ в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>играть ноябрь сей пора надоедать добавлять инт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>клара виснять,она бывать прозрачный вклеточка,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>хороший игра!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  rank  relevant  \\\n",
       "0           0   1     1         1   \n",
       "1           1   2     5         1   \n",
       "2           2   3     5         1   \n",
       "3           3   4     2         1   \n",
       "4           4   5     5         0   \n",
       "\n",
       "                                                text  \n",
       "0  расстраивать! пойти межсерверный битва, случат...  \n",
       "1  уважаемый разработчик, благодарить ваш ответ в...  \n",
       "2  играть ноябрь сей пора надоедать добавлять инт...  \n",
       "3  клара виснять,она бывать прозрачный вклеточка,...  \n",
       "4                                      хороший игра!  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('игра', 116)\n",
      "('уровень', 36)\n",
      "('играть', 27)\n",
      "('время', 20)\n",
      "('проходить', 20)\n",
      "('хотеть', 19)\n",
      "('игра,', 19)\n",
      "('сделать', 17)\n",
      "('который', 15)\n",
      "('реклама', 13)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "lemmata = []\n",
    "for index, row in clean_data.iterrows():\n",
    "    lemmata += row['text'].split()\n",
    "cnt = Counter(lemmata)\n",
    "for i in cnt.most_common(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import toktok\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "клара виснять , она бывать прозрачный вклеточка , а прогулка встретися голова мужик влезать длиться неделя , и ирема бывать рука голова , а бывать голова рука , да сделать покупка совершать оперетор 2 , надеяться быть услышать\n"
     ]
    }
   ],
   "source": [
    "toktok = toktok.ToktokTokenizer()\n",
    "print (toktok.tokenize(clean_data.text[3], return_str=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['клара', 'виснять', ',', 'она', 'бывать', 'прозрачный', 'вклеточка', ',', 'а', 'прогулка', 'встретися', 'голова', 'мужик', 'влезать', 'длиться', 'неделя', ',', 'и', 'ирема', 'бывать', 'рука', 'голова', ',', 'а', 'бывать', 'голова', 'рука', ',', 'да', 'сделать', 'покупка', 'совершать', 'оперетор', '2', ',', 'надеяться', 'быть', 'услышать']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(clean_data.text[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, tokenizer = toktok):\n",
    "    try:\n",
    "        return tokenizer.tokenize(text)\n",
    "    except:\n",
    "        return \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_data.text = clean_data.text.apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text, stemmer = RussianStemmer()):\n",
    "    try:\n",
    "        return \" \".join([stemmer.stem(w) for w in text.split()])\n",
    "    except:\n",
    "        return \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_data.text = clean_data.text.apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def cv(data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "\n",
    "    emb = count_vectorizer.fit_transform(data)\n",
    "\n",
    "    return emb, count_vectorizer\n",
    "\n",
    "list_corpus = clean_data[\"text\"].tolist()\n",
    "list_labels = clean_data[\"relevant\"].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, test_size=0.2, \n",
    "                                                                                random_state=40)\n",
    "\n",
    "X_train_counts, count_vectorizer = cv(X_train)\n",
    "X_test_counts = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(data):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    emb = tfidf_vectorizer.fit_transform(data)\n",
    "\n",
    "    return emb, tfidf_vectorizer\n",
    "\n",
    "list_corpus2 = clean_data[\"text\"].tolist()\n",
    "list_labels2 = clean_data[\"relevant\"].tolist()\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(list_corpus2, list_labels2, test_size=0.2, \n",
    "                                                                                random_state=40)\n",
    "\n",
    "X_train_counts2, count_vectorizer = tfidf(X_train)\n",
    "X_test_counts2 = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C=30.0, class_weight='balanced', solver='newton-cg', \n",
    "                         multi_class='multinomial', n_jobs=-1, random_state=40)\n",
    "clf.fit(X_train_counts, y_train)\n",
    "\n",
    "y_predicted_counts = clf.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.800, precision = 0.809, recall = 0.800, f1 = 0.796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "def get_metrics(y_test, y_predicted):  \n",
    "    # true positives / (true positives+false positives)\n",
    "    precision = precision_score(y_test, y_predicted, pos_label=None,\n",
    "                                    average='weighted')             \n",
    "    # true positives / (true positives + false negatives)\n",
    "    recall = recall_score(y_test, y_predicted, pos_label=None,\n",
    "                              average='weighted')\n",
    "    \n",
    "    # harmonic mean of precision and recall\n",
    "    f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')\n",
    "    \n",
    "    # true positives + true negatives/ total\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_predicted_counts)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_important_features(vectorizer, model, n=5):\n",
    "    index_to_word = {v:k for k,v in vectorizer.vocabulary_.items()}\n",
    "    \n",
    "    # loop for each class\n",
    "    classes ={}\n",
    "    for class_index in range(model.coef_.shape[0]):\n",
    "        word_importances = [(el, index_to_word[i]) for i,el in enumerate(model.coef_[class_index])]\n",
    "        sorted_coeff = sorted(word_importances, key = lambda x : x[0], reverse=True)\n",
    "        tops = sorted(sorted_coeff[:n], key = lambda x : x[0])\n",
    "        bottom = sorted_coeff[-n:]\n",
    "        classes[class_index] = {\n",
    "            'tops':tops,\n",
    "            'bottom':bottom\n",
    "        }\n",
    "    return classes\n",
    "\n",
    "importance = get_most_important_features(count_vectorizer, clf, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'tops': [(1.4071716211409298, 'наложница'),\n",
       "   (1.4173555432273628, 'играть'),\n",
       "   (1.4720274680678453, 'игра'),\n",
       "   (1.5383315835289286, 'добавлять'),\n",
       "   (1.642184398494618, 'мир'),\n",
       "   (1.7925109341555532, 'па'),\n",
       "   (1.8199381894462907, 'понравиться'),\n",
       "   (1.830701498790468, 'причина'),\n",
       "   (1.8523870574681092, 'приложение'),\n",
       "   (2.114630011259471, 'скачать')],\n",
       "  'bottom': [(-0.5273560343634993, 'смысл'),\n",
       "   (-0.5587068417281483, 'крутой'),\n",
       "   (-0.6193784035009469, 'взламывать'),\n",
       "   (-0.6753714252759399, 'вообще'),\n",
       "   (-0.6837148869861721, 'этот'),\n",
       "   (-0.8101411085838699, 'создавать'),\n",
       "   (-0.8244338019320747, 'соответствовать'),\n",
       "   (-1.0715003433846142, 'класный'),\n",
       "   (-1.077979311479725, 'любовь'),\n",
       "   (-1.077979311479725, 'храм')]}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = LogisticRegression(C=30.0, class_weight='balanced', solver='newton-cg', \n",
    "                         multi_class='multinomial', n_jobs=-1, random_state=40)\n",
    "clf2.fit(X_train_counts2, y_train2)\n",
    "\n",
    "y_predicted_counts2 = clf.predict(X_test_counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.550, precision = 0.303, recall = 0.550, f1 = 0.390\n"
     ]
    }
   ],
   "source": [
    "accuracy2, precision2, recall2, f12 = get_metrics(y_test2, y_predicted_counts2)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy2, precision2, recall2, f12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_naive = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_naive = {\n",
    "             'alpha':[1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'alpha': [1, 0.1, 0.01, 0.001, 0.0001, 1e-05]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_naive = GridSearchCV(clf_naive, param_dist_naive, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "grid_naive.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-05}\n",
      "0.8154680921671769\n",
      "MultinomialNB(alpha=1e-05, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "print(grid_naive.best_params_)\n",
    "print(grid_naive.best_score_)\n",
    "print(grid_naive.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_naive = grid_naive.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.625, precision = 0.736, recall = 0.625, f1 = 0.596\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred_naive)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_svc = {\n",
    "             'C':[1,10,100,1000],\n",
    "             'gamma':[1,0.1,0.001,0.0001], \n",
    "             'kernel':['linear','rbf','sigmoid']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': [1, 10, 100, 1000], 'gamma': [1, 0.1, 0.001, 0.0001], 'kernel': ['linear', 'rbf', 'sigmoid']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svc = GridSearchCV(clf_svc, param_dist_svc, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "grid_svc.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.835221787436924\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_svc.best_params_)\n",
    "print(grid_svc.best_score_)\n",
    "print(grid_svc.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc = grid_svc.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.850, precision = 0.850, recall = 0.850, f1 = 0.850\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred_svc)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_rf = {\n",
    "    'n_estimators': [5, 10, 20, 40],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [1, 3, 5, 7, 9, None],\n",
    "    'min_samples_leaf': [1, 2, 4, 8, 16]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [5, 10, 20, 40], 'criterion': ['gini', 'entropy'], 'max_depth': [1, 3, 5, 7, 9, None], 'min_samples_leaf': [1, 2, 4, 8, 16]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_forest = GridSearchCV(clf_rf, param_dist_rf, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "grid_forest.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 2, 'n_estimators': 40}\n",
      "0.8122284654415074\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=2, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_forest.best_params_)\n",
    "print(grid_forest.best_score_)\n",
    "print(grid_forest.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = grid_forest.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.800, precision = 0.816, recall = 0.800, f1 = 0.800\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred_rf)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
