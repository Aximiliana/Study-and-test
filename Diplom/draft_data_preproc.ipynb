{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "random.seed(1228)\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "import numpy as np\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 analize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_raw22.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>relevant</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\\tЯ очень расстроена! Пошли в межсерверную бит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>\\tУважаемые разработчики, благодарю за ваш отв...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>\\tИграю с ноября. До сих пор не надоедает. Доб...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>\\tУ меня Клара виснит,она бывает прозрачной ил...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>\\tЛучшая игра!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  rank  relevant                                               text\n",
       "0   1     1         1  \\tЯ очень расстроена! Пошли в межсерверную бит...\n",
       "1   2     5         1  \\tУважаемые разработчики, благодарю за ваш отв...\n",
       "2   3     5         1  \\tИграю с ноября. До сих пор не надоедает. Доб...\n",
       "3   4     2         1  \\tУ меня Клара виснит,она бывает прозрачной ил...\n",
       "4   5     5         0                                     \\tЛучшая игра!"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214 entries, 0 to 213\n",
      "Data columns (total 4 columns):\n",
      "id          214 non-null int64\n",
      "rank        214 non-null int64\n",
      "relevant    214 non-null int64\n",
      "text        214 non-null object\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 6.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    119\n",
       "0     95\n",
       "Name: relevant, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['relevant'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>relevant</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>я очень расстроена! пошли в межсерверную битв...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>уважаемые разработчики, благодарю за ваш отве...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>играю с ноября  до сих пор не надоедает  доба...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>у меня клара виснит,она бывает прозрачной или...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>лучшая игра!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  rank  relevant                                               text\n",
       "0   1     1         1   я очень расстроена! пошли в межсерверную битв...\n",
       "1   2     5         1   уважаемые разработчики, благодарю за ваш отве...\n",
       "2   3     5         1   играю с ноября  до сих пор не надоедает  доба...\n",
       "3   4     2         1   у меня клара виснит,она бывает прозрачной или...\n",
       "4   5     5         0                                       лучшая игра!"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardize_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[^А-Яа-я0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\", \"at\")\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    return df\n",
    "\n",
    "data = standardize_text(data, \"text\")\n",
    "\n",
    "data.to_csv(\"clean_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>relevant</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>209</td>\n",
       "      <td>210</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>просят написать отзыв</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>приятная игра  иной раз сложная, но в меру  д...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>интересная игра для людей всех возрастов  спо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>212</td>\n",
       "      <td>213</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>игра очень нравится</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>213</td>\n",
       "      <td>214</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>игра хорошая, но нервы нужны крепкие  пока те...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   id  rank  relevant  \\\n",
       "209         209  210     3         0   \n",
       "210         210  211     5         1   \n",
       "211         211  212     5         1   \n",
       "212         212  213     5         0   \n",
       "213         213  214     1         1   \n",
       "\n",
       "                                                  text  \n",
       "209                              просят написать отзыв  \n",
       "210   приятная игра  иной раз сложная, но в меру  д...  \n",
       "211   интересная игра для людей всех возрастов  спо...  \n",
       "212                                игра очень нравится  \n",
       "213   игра хорошая, но нервы нужны крепкие  пока те...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = pd.read_csv(\"clean_data.csv\")\n",
    "clean_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    214.000000\n",
       "mean     147.551402\n",
       "std      143.107710\n",
       "min        6.000000\n",
       "25%       31.250000\n",
       "50%       97.500000\n",
       "75%      222.500000\n",
       "max      520.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_data = clean_data.text.apply(len)\n",
    "len_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2576a46a20f4e88aa313c345415881a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=214), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('не', 179)\n",
      "('и', 153)\n",
      "('в', 103)\n",
      "('игра', 87)\n",
      "('я', 70)\n",
      "('что', 65)\n",
      "('а', 61)\n",
      "('на', 61)\n",
      "('за', 43)\n",
      "('но', 43)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "cnt = Counter()\n",
    "n_types = []\n",
    "n_tokens = []\n",
    "tokens = []\n",
    "for index, row in tqdm(clean_data.iterrows(), total = len(clean_data)):\n",
    "    tokens = row['text'].split()\n",
    "    cnt.update(tokens)\n",
    "    n_types.append(len(cnt))\n",
    "    n_tokens.append(sum(cnt.values()))\n",
    "for i in cnt.most_common(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization, lemmatisation, delete stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import toktok\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "\n",
    "import gensim\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "у меня клара виснит , она бывает прозрачной или вклеточку , а если на прогулке встретися то голова мужика влезает и так уже длится неделю , и у ирем бывает нет рук или головы , а бывает нет и головы и рук у не , да и сделайте чтобы покупки можно было совершать через оперетора 2 , надеюсь я буду услышана\n"
     ]
    }
   ],
   "source": [
    "toktok = toktok.ToktokTokenizer()\n",
    "print (toktok.tokenize(clean_data.text[3], return_str=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['у', 'меня', 'клара', 'виснит', ',', 'она', 'бывает', 'прозрачной', 'или', 'вклеточку', ',', 'а', 'если', 'на', 'прогулке', 'встретися', 'то', 'голова', 'мужика', 'влезает', 'и', 'так', 'уже', 'длится', 'неделю', ',', 'и', 'у', 'ирем', 'бывает', 'нет', 'рук', 'или', 'головы', ',', 'а', 'бывает', 'нет', 'и', 'головы', 'и', 'рук', 'у', 'не', ',', 'да', 'и', 'сделайте', 'чтобы', 'покупки', 'можно', 'было', 'совершать', 'через', 'оперетора', '2', ',', 'надеюсь', 'я', 'буду', 'услышана']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(clean_data.text[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, tokenizer = toktok):\n",
    "    try:\n",
    "        return tokenizer.tokenize(text)\n",
    "    except:\n",
    "        return \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_data.text = clean_data.text.apply(tokenize)\n",
    "#clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "#print(tokenizer.tokenize(clean_data.text[3]))\n",
    "#clean_data.text = clean_data[\"text\"].apply(tokenizer.tokenize)\n",
    "#clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystopwords = stopwords.words('russian') + ['это', 'наш' , 'тыс', 'млн', 'млрд', 'также',  'т', 'д', \n",
    "                                            'мой', 'очень', 'день', ',', 'просто', 'этот', 'вообще','что',\n",
    "                                            'так', 'вот', 'быть', 'как', 'в', '—', '–', 'к', 'на', '...',]\n",
    "def  remove_stopwords(text, mystopwords = mystopwords):\n",
    "    try:\n",
    "        return \" \".join([token for token in text.split() if not token in mystopwords])\n",
    "    except:\n",
    "        return \"ошибка\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>relevant</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>расстроена! пошли межсерверную битву, случился...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>уважаемые разработчики, благодарю ваш ответ во...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>играю ноября сих пор надоедает добавляет интер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>клара виснит,она бывает прозрачной вклеточку,а...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>лучшая игра!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  rank  relevant  \\\n",
       "0           0   1     1         1   \n",
       "1           1   2     5         1   \n",
       "2           2   3     5         1   \n",
       "3           3   4     2         1   \n",
       "4           4   5     5         0   \n",
       "\n",
       "                                                text  \n",
       "0  расстроена! пошли межсерверную битву, случился...  \n",
       "1  уважаемые разработчики, благодарю ваш ответ во...  \n",
       "2  играю ноября сих пор надоедает добавляет интер...  \n",
       "3  клара виснит,она бывает прозрачной вклеточку,а...  \n",
       "4                                       лучшая игра!  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.text = clean_data.text.apply(remove_stopwords) \n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokinize + stowords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_ru(file_text):\n",
    "# firstly let's apply nltk tokenization\n",
    "    tokens = word_tokenize(file_text)\n",
    "\n",
    "# let's delete punctuation symbols\n",
    "    tokens = [i for i in tokens if (i not in string.punctuation)]\n",
    "\n",
    "# deleting stop_words\n",
    "    stop_words = stopwords.words('russian')\n",
    "    stop_words.extend(['что', 'это', 'так', 'вот', 'быть', 'как', 'в', '—', '–', 'к', 'на', '...',\n",
    "                       'наш' , 'тыс', 'млн', 'млрд', 'также',  'т', 'д', 'е',\n",
    "                        'мой', 'очень', 'день', ',', 'просто', 'этот', 'вообще'])\n",
    "    tokens = [i for i in tokens if (i not in stop_words)]\n",
    "\n",
    "# cleaning words\n",
    "    tokens = [i.replace(\"«\", \"\").replace(\"»\", \"\") for i in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>relevant</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>я очень расстроена! пошли в межсерверную битв...</td>\n",
       "      <td>[расстроена, пошли, межсерверную, битву, случи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>уважаемые разработчики, благодарю за ваш отве...</td>\n",
       "      <td>[уважаемые, разработчики, благодарю, ваш, отве...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>играю с ноября  до сих пор не надоедает  доба...</td>\n",
       "      <td>[играю, ноября, сих, пор, надоедает, добавляет...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>у меня клара виснит,она бывает прозрачной или...</td>\n",
       "      <td>[клара, виснит, бывает, прозрачной, вклеточку,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>лучшая игра!</td>\n",
       "      <td>[лучшая, игра]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  rank  relevant  \\\n",
       "0           0   1     1         1   \n",
       "1           1   2     5         1   \n",
       "2           2   3     5         1   \n",
       "3           3   4     2         1   \n",
       "4           4   5     5         0   \n",
       "\n",
       "                                                text  \\\n",
       "0   я очень расстроена! пошли в межсерверную битв...   \n",
       "1   уважаемые разработчики, благодарю за ваш отве...   \n",
       "2   играю с ноября  до сих пор не надоедает  доба...   \n",
       "3   у меня клара виснит,она бывает прозрачной или...   \n",
       "4                                       лучшая игра!   \n",
       "\n",
       "                                              tokens  \n",
       "0  [расстроена, пошли, межсерверную, битву, случи...  \n",
       "1  [уважаемые, разработчики, благодарю, ваш, отве...  \n",
       "2  [играю, ноября, сих, пор, надоедает, добавляет...  \n",
       "3  [клара, виснит, бывает, прозрачной, вклеточку,...  \n",
       "4                                     [лучшая, игра]  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data['tokens'] = clean_data.text.apply(tokenize_ru)\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f28a9ab7af4ede89e86250c74bc6ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=214), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('игра', 103)\n",
      "('игру', 29)\n",
      "('играть', 17)\n",
      "('время', 16)\n",
      "('уровень', 16)\n",
      "('уровни', 15)\n",
      "('разработчики', 14)\n",
      "('игре', 14)\n",
      "('пройти', 14)\n",
      "(\"''\", 13)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "cnt = Counter()\n",
    "n_types = []\n",
    "n_tokens = []\n",
    "tokens = []\n",
    "for index, row in tqdm(clean_data.iterrows(), total = len(clean_data)):\n",
    "    tokens = row['text']\n",
    "    cnt.update(tokens)\n",
    "    n_types.append(len(cnt))\n",
    "    n_tokens.append(sum(cnt.values()))\n",
    "for i in cnt.most_common(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokinize + stowords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.2 ms, sys: 9.76 ms, total: 36 ms\n",
      "Wall time: 1.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from pymystem3 import Mystem\n",
    "\n",
    "m = Mystem()\n",
    "def lemmatize(text, mystem=m):\n",
    "    try:\n",
    "        return \"\".join(m.lemmatize(text)).strip()  \n",
    "    except:\n",
    "        return \" \"\n",
    "\n",
    "clean_data.text = clean_data.text.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "у я клара виснять,она бывать прозрачный или вклеточка,а если на прогулка встретися то голова мужик влезать и так уже длиться неделя,и у ирема бывать нет рука или голова,а бывать нет и голова и рука у не ,да и сделать чтобы покупка можно быть совершать через оперетор     2, надеяться я быть услышать\n"
     ]
    }
   ],
   "source": [
    "text =  clean_data.text[3]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'клара', 'виснит', 'бывает', 'прозрачной', 'вклеточку', 'прогулке', 'встретися', 'голова', 'мужика', 'влезает', 'длится', 'неделю', 'ирем', 'бывает', 'рук', 'головы', 'бывает', 'головы', 'рук', 'сделайте', 'покупки', 'совершать', 'оперетора', '2', 'надеюсь', 'буду', 'услышана'\n",
      "клара, виснит, бывает, прозрачной, вклеточку, прогулке, встретися, голова, мужика, влезает, длится, неделю, ирем, бывает, рук, головы, бывает, головы, рук, сделайте, покупки, совершать, оперетора, 2, надеюсь, буду, услышана\n"
     ]
    }
   ],
   "source": [
    "print(str(clean_data.text[3]).strip('[]'))\n",
    "print( ', '.join(map(str, clean_data.text[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemma true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmas (text):\n",
    "    tmp = []\n",
    "    for w in text:\n",
    "        word = morph.parse(w)[0].normal_form\n",
    "        tmp.append(word)\n",
    "    return tmp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['клара', 'виснит', 'бывать', 'прозрачный', 'вклеточка', 'прогулка', 'встретися', 'голова', 'мужик', 'влезать', 'длиться', 'неделя', 'ирем', 'бывать', 'рука', 'голов', 'бывать', 'голов', 'рука', 'сделать', 'покупка', 'совершать', 'оперетор', '2', 'надеяться', 'быть', 'услышать']\n"
     ]
    }
   ],
   "source": [
    "lemma = lemmas(clean_data.text[3])\n",
    "print(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.text = clean_data.tokens.apply(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>relevant</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[расстроить, послать, межсерверный, битва, слу...</td>\n",
       "      <td>[расстроена, пошли, межсерверную, битву, случи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[уважаемый, разработчик, благодарить, ваш, отв...</td>\n",
       "      <td>[уважаемые, разработчики, благодарю, ваш, отве...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[играть, ноябрь, сей, пора, надоедать, добавля...</td>\n",
       "      <td>[играю, ноября, сих, пор, надоедает, добавляет...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[клара, виснит, бывать, прозрачный, вклеточка,...</td>\n",
       "      <td>[клара, виснит, бывает, прозрачной, вклеточку,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[хороший, игра]</td>\n",
       "      <td>[лучшая, игра]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[ужасный, игра, разработчик, смотреть, мнение,...</td>\n",
       "      <td>[ужасная, игра, разработчики, смотрят, мнения,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[сказать, честно, игра, интернет, нравиться, м...</td>\n",
       "      <td>[скажу, честно, игра, интернете, нравится, мин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[игра, напрямую, конвертировать, твой, время, ...</td>\n",
       "      <td>[игра, напрямую, конвертирующая, твое, время, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[игра, реклама, соответствовать]</td>\n",
       "      <td>[игра, рекламе, соответствует]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[игра, класный, играть, удовольствие, счёт, ал...</td>\n",
       "      <td>[игра, класная, играю, удовольствием, счет, ал...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[очки, добавляться, приготовление, блюдо, неск...</td>\n",
       "      <td>[очки, добавляются, приготовлении, блюд, неско...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[интересный, игра]</td>\n",
       "      <td>[интересная, игра]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[хотеть, обратить, ваш, внимание, народ, допус...</td>\n",
       "      <td>[хочу, обратить, ваше, внимание, народ, допуск...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[вообшеть, хотеть, ставить, звезда, тупой, при...</td>\n",
       "      <td>[вообшето, хотела, ставить, звезду, тупое, при...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[реклама, 1, звезда]</td>\n",
       "      <td>[рекламу, 1, звезда]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  id  rank  relevant  \\\n",
       "0            0   1     1         1   \n",
       "1            1   2     5         1   \n",
       "2            2   3     5         1   \n",
       "3            3   4     2         1   \n",
       "4            4   5     5         0   \n",
       "5            5   6     2         0   \n",
       "6            6   7     3         0   \n",
       "7            7   8     1         1   \n",
       "8            8   9     3         0   \n",
       "9            9  10     5         1   \n",
       "10          10  11     1         1   \n",
       "11          11  12     5         0   \n",
       "12          12  13     1         1   \n",
       "13          13  14     1         1   \n",
       "14          14  15     1         0   \n",
       "\n",
       "                                                 text  \\\n",
       "0   [расстроить, послать, межсерверный, битва, слу...   \n",
       "1   [уважаемый, разработчик, благодарить, ваш, отв...   \n",
       "2   [играть, ноябрь, сей, пора, надоедать, добавля...   \n",
       "3   [клара, виснит, бывать, прозрачный, вклеточка,...   \n",
       "4                                     [хороший, игра]   \n",
       "5   [ужасный, игра, разработчик, смотреть, мнение,...   \n",
       "6   [сказать, честно, игра, интернет, нравиться, м...   \n",
       "7   [игра, напрямую, конвертировать, твой, время, ...   \n",
       "8                    [игра, реклама, соответствовать]   \n",
       "9   [игра, класный, играть, удовольствие, счёт, ал...   \n",
       "10  [очки, добавляться, приготовление, блюдо, неск...   \n",
       "11                                 [интересный, игра]   \n",
       "12  [хотеть, обратить, ваш, внимание, народ, допус...   \n",
       "13  [вообшеть, хотеть, ставить, звезда, тупой, при...   \n",
       "14                               [реклама, 1, звезда]   \n",
       "\n",
       "                                               tokens  \n",
       "0   [расстроена, пошли, межсерверную, битву, случи...  \n",
       "1   [уважаемые, разработчики, благодарю, ваш, отве...  \n",
       "2   [играю, ноября, сих, пор, надоедает, добавляет...  \n",
       "3   [клара, виснит, бывает, прозрачной, вклеточку,...  \n",
       "4                                      [лучшая, игра]  \n",
       "5   [ужасная, игра, разработчики, смотрят, мнения,...  \n",
       "6   [скажу, честно, игра, интернете, нравится, мин...  \n",
       "7   [игра, напрямую, конвертирующая, твое, время, ...  \n",
       "8                      [игра, рекламе, соответствует]  \n",
       "9   [игра, класная, играю, удовольствием, счет, ал...  \n",
       "10  [очки, добавляются, приготовлении, блюд, неско...  \n",
       "11                                 [интересная, игра]  \n",
       "12  [хочу, обратить, ваше, внимание, народ, допуск...  \n",
       "13  [вообшето, хотела, ставить, звезду, тупое, при...  \n",
       "14                               [рекламу, 1, звезда]  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab0407bafeb4483bbfc8c864b5ee6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=214), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('игра', 159)\n",
      "('уровень', 52)\n",
      "('играть', 36)\n",
      "('время', 28)\n",
      "('хотеть', 21)\n",
      "('пройти', 20)\n",
      "('разработчик', 18)\n",
      "('сделать', 18)\n",
      "('реклама', 18)\n",
      "('который', 16)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "cnt = Counter()\n",
    "n_types = []\n",
    "n_tokens = []\n",
    "tokens = []\n",
    "for index, row in tqdm(clean_data.iterrows(), total = len(clean_data)):\n",
    "    tokens = row['text']\n",
    "    cnt.update(tokens)\n",
    "    n_types.append(len(cnt))\n",
    "    n_tokens.append(sum(cnt.values()))\n",
    "for i in cnt.most_common(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemma true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('игра', 122)\n",
      "('уровень', 36)\n",
      "('играть', 27)\n",
      "('время', 22)\n",
      "('проходить', 20)\n",
      "('хотеть', 19)\n",
      "('игра,', 19)\n",
      "('сделать', 17)\n",
      "('который', 15)\n",
      "('реклама', 13)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "lemmata = []\n",
    "for index, row in clean_data.iterrows():\n",
    "    lemmata += row['text'].split()\n",
    "cnt = Counter(lemmata)\n",
    "for i in cnt.most_common(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text, stemmer = RussianStemmer()):\n",
    "    try:\n",
    "        return \" \".join([stemmer.stem(w) for w in text.split()])\n",
    "    except:\n",
    "        return \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_data.text = clean_data.text.apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_corpus = clean_data[\"text\"].tolist()\n",
    "list_labels = clean_data[\"relevant\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-c6b5c8e0370e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                                                                 random_state=40)\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mX_train_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mX_test_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-c6b5c8e0370e>\u001b[0m in \u001b[0;36mcv\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcount_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#analyzer='word', decode_error='replace', lowercase=False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1031\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not iterable"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def cv(data):\n",
    "    count_vectorizer = CountVectorizer(analyzer=callable, lowercase=False)\n",
    "#analyzer='word', decode_error='replace', lowercase=False \n",
    "    emb = count_vectorizer.fit_transform(data)\n",
    "\n",
    "    return emb, count_vectorizer\n",
    "\n",
    "list_corpus = clean_data[\"text\"].tolist()\n",
    "list_labels = clean_data[\"relevant\"].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, test_size=0.3, \n",
    "                                                                                random_state=40)\n",
    "\n",
    "X_train_counts, count_vectorizer = cv(X_train)\n",
    "X_test_counts = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'клара': 10, 'виснять': 2, 'она': 14, 'бывать': 0, 'прозрачный': 18, 'вклеточка': 3, 'прогулка': 17, 'встретися': 5, 'голова': 6, 'мужик': 11, 'влезать': 4, 'длиться': 8, 'неделя': 13, 'ирема': 9, 'рука': 19, 'да': 7, 'сделать': 20, 'покупка': 16, 'совершать': 21, 'оперетор': 15, 'надеяться': 12, 'быть': 1, 'услышать': 22}\n",
      "(1, 23)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[3 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "text = clean_data.text[3]\n",
    "lisst = []\n",
    "lisst.append(text)\n",
    "# create the transform\n",
    "vectorizer = CountVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(lisst)\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "# encode document\n",
    "vector = vectorizer.transform(lisst)\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(type(vector))\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(data):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    emb = tfidf_vectorizer.fit_transform(data)\n",
    "\n",
    "    return emb, tfidf_vectorizer\n",
    "\n",
    "list_corpus2 = clean_data[\"text\"].tolist()\n",
    "list_labels2 = clean_data[\"relevant\"].tolist()\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(list_corpus2, list_labels2, test_size=0.2, \n",
    "                                                                                random_state=40)\n",
    "\n",
    "X_train_counts2, count_vectorizer = tfidf(X_train)\n",
    "X_test_counts2 = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<149x1048 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1992 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C=30.0, class_weight='balanced', solver='newton-cg', \n",
    "                         multi_class='multinomial', n_jobs=-1, random_state=40)\n",
    "clf.fit(X_train_counts, y_train)\n",
    "\n",
    "y_predicted_counts = clf.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.800, precision = 0.809, recall = 0.800, f1 = 0.796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "def get_metrics(y_test, y_predicted):  \n",
    "    # true positives / (true positives+false positives)\n",
    "    precision = precision_score(y_test, y_predicted, pos_label=None,\n",
    "                                    average='weighted')             \n",
    "    # true positives / (true positives + false negatives)\n",
    "    recall = recall_score(y_test, y_predicted, pos_label=None,\n",
    "                              average='weighted')\n",
    "    \n",
    "    # harmonic mean of precision and recall\n",
    "    f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')\n",
    "    \n",
    "    # true positives + true negatives/ total\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_predicted_counts)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_important_features(vectorizer, model, n=5):\n",
    "    index_to_word = {v:k for k,v in vectorizer.vocabulary_.items()}\n",
    "    \n",
    "    # loop for each class\n",
    "    classes ={}\n",
    "    for class_index in range(model.coef_.shape[0]):\n",
    "        word_importances = [(el, index_to_word[i]) for i,el in enumerate(model.coef_[class_index])]\n",
    "        sorted_coeff = sorted(word_importances, key = lambda x : x[0], reverse=True)\n",
    "        tops = sorted(sorted_coeff[:n], key = lambda x : x[0])\n",
    "        bottom = sorted_coeff[-n:]\n",
    "        classes[class_index] = {\n",
    "            'tops':tops,\n",
    "            'bottom':bottom\n",
    "        }\n",
    "    return classes\n",
    "\n",
    "importance = get_most_important_features(count_vectorizer, clf, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'tops': [(1.4071716211409298, 'наложница'),\n",
       "   (1.4173555432273628, 'играть'),\n",
       "   (1.4720274680678453, 'игра'),\n",
       "   (1.5383315835289286, 'добавлять'),\n",
       "   (1.642184398494618, 'мир'),\n",
       "   (1.7925109341555532, 'па'),\n",
       "   (1.8199381894462907, 'понравиться'),\n",
       "   (1.830701498790468, 'причина'),\n",
       "   (1.8523870574681092, 'приложение'),\n",
       "   (2.114630011259471, 'скачать')],\n",
       "  'bottom': [(-0.5273560343634993, 'смысл'),\n",
       "   (-0.5587068417281483, 'крутой'),\n",
       "   (-0.6193784035009469, 'взламывать'),\n",
       "   (-0.6753714252759399, 'вообще'),\n",
       "   (-0.6837148869861721, 'этот'),\n",
       "   (-0.8101411085838699, 'создавать'),\n",
       "   (-0.8244338019320747, 'соответствовать'),\n",
       "   (-1.0715003433846142, 'класный'),\n",
       "   (-1.077979311479725, 'любовь'),\n",
       "   (-1.077979311479725, 'храм')]}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = LogisticRegression(C=30.0, class_weight='balanced', solver='newton-cg', \n",
    "                         multi_class='multinomial', n_jobs=-1, random_state=40)\n",
    "clf2.fit(X_train_counts2, y_train2)\n",
    "\n",
    "y_predicted_counts2 = clf.predict(X_test_counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.550, precision = 0.303, recall = 0.550, f1 = 0.390\n"
     ]
    }
   ],
   "source": [
    "accuracy2, precision2, recall2, f12 = get_metrics(y_test2, y_predicted_counts2)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy2, precision2, recall2, f12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_naive = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_naive = {\n",
    "             'alpha':[1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'alpha': [1, 0.1, 0.01, 0.001, 0.0001, 1e-05]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_naive = GridSearchCV(clf_naive, param_dist_naive, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "grid_naive.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-05}\n",
      "0.8154680921671769\n",
      "MultinomialNB(alpha=1e-05, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "print(grid_naive.best_params_)\n",
    "print(grid_naive.best_score_)\n",
    "print(grid_naive.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_naive = grid_naive.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.625, precision = 0.736, recall = 0.625, f1 = 0.596\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred_naive)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_svc = {\n",
    "             'C':[1,10,100,1000],\n",
    "             'gamma':[1,0.1,0.001,0.0001], \n",
    "             'kernel':['linear','rbf','sigmoid']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': [1, 10, 100, 1000], 'gamma': [1, 0.1, 0.001, 0.0001], 'kernel': ['linear', 'rbf', 'sigmoid']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svc = GridSearchCV(clf_svc, param_dist_svc, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "grid_svc.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.835221787436924\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_svc.best_params_)\n",
    "print(grid_svc.best_score_)\n",
    "print(grid_svc.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc = grid_svc.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.850, precision = 0.850, recall = 0.850, f1 = 0.850\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred_svc)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_rf = {\n",
    "    'n_estimators': [5, 10, 20, 40],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [1, 3, 5, 7, 9, None],\n",
    "    'min_samples_leaf': [1, 2, 4, 8, 16]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [5, 10, 20, 40], 'criterion': ['gini', 'entropy'], 'max_depth': [1, 3, 5, 7, 9, None], 'min_samples_leaf': [1, 2, 4, 8, 16]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_forest = GridSearchCV(clf_rf, param_dist_rf, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "grid_forest.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 2, 'n_estimators': 40}\n",
      "0.8122284654415074\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=2, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_forest.best_params_)\n",
    "print(grid_forest.best_score_)\n",
    "print(grid_forest.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = grid_forest.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.800, precision = 0.816, recall = 0.800, f1 = 0.800\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred_rf)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
